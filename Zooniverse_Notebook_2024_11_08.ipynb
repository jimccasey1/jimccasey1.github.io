{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9TEiPfdPtuIKDnWZTZsIA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimccasey1/jimccasey1.github.io/blob/master/Zooniverse_Notebook_2024_11_08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zooniverse Caesar Aggregation - Google Colab Version\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Before you begin, you need:\n",
        "\n",
        "1. **Classification Export CSV** from your Zooniverse project\n",
        "   - Go to your project's Lab page\n",
        "   - Click on Data Exports\n",
        "   - Request a new classification export\n",
        "   - Download when ready\n",
        "\n",
        "2. **Workflow CSV** from your Zooniverse project\n",
        "   - Same location as classification export\n",
        "   - Download the workflow export\n",
        "\n",
        "3. **Workflow ID**\n",
        "   - Found in project builder URL when editing your workflow\n",
        "   - Example: In `https://www.zooniverse.org/lab/12345/workflows/67890`\n",
        "   - `67890` is your workflow ID\n",
        "\n",
        "4. **Workflow Version**\n",
        "   - Found in your workflow export CSV\n",
        "   - Latest version number for your workflow ID"
      ],
      "metadata": {
        "id": "nJ9NoPYAzTFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial Setup\n",
        "\n",
        "⚠️ **IMPORTANT**: This notebook must be run in a specific order to work correctly in Google Colab. Follow these steps exactly:"
      ],
      "metadata": {
        "id": "PFDFn-oNzco5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Initial Package Cleanup"
      ],
      "metadata": {
        "id": "EN6B3FqWzdus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove existing packages\n",
        "!pip uninstall -y pandas\n",
        "!pip uninstall -y mizani\n",
        "!pip uninstall -y plotnine\n",
        "!pip cache purge\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXKf__zazhq8",
        "outputId": "2cd17551-bb24-4839-d22a-c6a985202657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pandas 2.2.2\n",
            "Uninstalling pandas-2.2.2:\n",
            "  Successfully uninstalled pandas-2.2.2\n",
            "Found existing installation: mizani 0.13.0\n",
            "Uninstalling mizani-0.13.0:\n",
            "  Successfully uninstalled mizani-0.13.0\n",
            "Found existing installation: plotnine 0.14.1\n",
            "Uninstalling plotnine-0.14.1:\n",
            "  Successfully uninstalled plotnine-0.14.1\n",
            "Files removed: 163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Install Correct Pandas Version"
      ],
      "metadata": {
        "id": "CMyj7HXCziry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Force install the correct pandas version\n",
        "!pip install pandas==2.2.2 --force-reinstall --no-deps\n",
        "!pip install -I pandas==2.2.2  # -I means ignore installed packages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "MhhNhTtBzlw3",
        "outputId": "da6e742b-2a2f-4a95-f7ac-d10ff43b2cac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas==2.2.2\n",
            "  Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.3\n",
            "    Uninstalling pandas-2.1.3:\n",
            "      Successfully uninstalled pandas-2.1.3\n",
            "Successfully installed pandas-2.2.2\n",
            "Collecting pandas==2.2.2\n",
            "  Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting numpy>=1.22.4 (from pandas==2.2.2)\n",
            "  Using cached numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas==2.2.2)\n",
            "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas==2.2.2)\n",
            "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas==2.2.2)\n",
            "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas==2.2.2)\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "Using cached numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
            "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
            "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pytz, tzdata, six, numpy, python-dateutil, pandas\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.1.3 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.1.3 which is incompatible.\n",
            "langchain 0.3.4 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.1.3 which is incompatible.\n",
            "matplotlib 3.8.0 requires numpy<2,>=1.21, but you have numpy 2.1.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.3 which is incompatible.\n",
            "panoptes-aggregation 4.1.0 requires numpy<1.26.3,>=1.22.0, but you have numpy 2.1.3 which is incompatible.\n",
            "panoptes-aggregation 4.1.0 requires pandas<2.1.4,>=1.4.0, but you have pandas 2.2.2 which is incompatible.\n",
            "pytensor 2.25.5 requires numpy<2,>=1.17.0, but you have numpy 2.1.3 which is incompatible.\n",
            "scikit-learn 1.3.2 requires numpy<2.0,>=1.17.3, but you have numpy 2.1.3 which is incompatible.\n",
            "scipy 1.11.3 requires numpy<1.28.0,>=1.21.6, but you have numpy 2.1.3 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.1.3 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.2 pandas-2.2.2 python-dateutil-2.8.2 pytz-2024.2 six-1.16.0 tzdata-2024.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "pytz",
                  "six"
                ]
              },
              "id": "af16afb95b3d4eecba5a1fc9bbc99ef3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: First Version Check"
      ],
      "metadata": {
        "id": "K4fDTGdAzqiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify pandas version\n",
        "import pandas as pd\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "\n",
        "# If pandas version is not 2.2.2:\n",
        "# 1. Restart runtime (Runtime > Restart runtime)\n",
        "# 2. Run Step 2 again\n",
        "# 3. Run this version check again"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kjn_xmYFzvQx",
        "outputId": "2f38280c-113d-4e76-e638-54846df3de16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas version: 2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Install Required Packages"
      ],
      "metadata": {
        "id": "2VRm05pnzxnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Only proceed if pandas version shows 2.2.2\n",
        "\n",
        "# Install build dependencies first\n",
        "!apt-get update\n",
        "!apt-get install -y build-essential python3-dev\n",
        "\n",
        "# Install scientific computing dependencies\n",
        "!pip install numpy\n",
        "!pip install scipy\n",
        "!pip install scikit-learn\n",
        "\n",
        "# Uninstall existing panoptes installation if any\n",
        "!pip uninstall -y panoptes-aggregation\n",
        "\n",
        "# Install fresh from GitHub\n",
        "!pip install -U git+https://github.com/zooniverse/aggregation-for-caesar.git\n",
        "\n",
        "# Install remaining packages\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q4R_IWGzyfv",
        "outputId": "522298de-bdff-4de7-cbd7-64bf36550182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [1 InRelease 5,481 B/129 kB 4%] [Connected to\r                                                                                                    \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Fetched 264 kB in 1s (202 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "python3-dev is already the newest version (3.10.6-1~22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.3)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.26.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.2)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Found existing installation: panoptes_aggregation 4.1.0\n",
            "Uninstalling panoptes_aggregation-4.1.0:\n",
            "  Successfully uninstalled panoptes_aggregation-4.1.0\n",
            "Collecting git+https://github.com/zooniverse/aggregation-for-caesar.git\n",
            "  Cloning https://github.com/zooniverse/aggregation-for-caesar.git to /tmp/pip-req-build-xdm6515a\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/zooniverse/aggregation-for-caesar.git /tmp/pip-req-build-xdm6515a\n",
            "  Resolved https://github.com/zooniverse/aggregation-for-caesar.git to commit c8a9fffb5228b962515eecd96e852ae0aebaa681\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4<4.13,>=4.8.1 in /usr/local/lib/python3.10/dist-packages (from panoptes_aggregation==4.1.0) (4.12.3)\n",
            "Requirement already satisfied: collatex<2.4,>=2.3 in /usr/local/lib/python3.10/dist-packages (from panoptes_aggregation==4.1.0) (2.3)\n",
            "Requirement already satisfied: hdbscan<=0.8.33,>=0.8.20 in /usr/local/lib/python3.10/dist-packages (from panoptes_aggregation==4.1.0) (0.8.33)\n",
            "Requirement already satisfied: lxml<4.10,>=4.4 in /usr/local/lib/python3.10/dist-packages (from panoptes_aggregation==4.1.0) (4.9.4)\n",
            "Requirement already satisfied: numpy<1.26.3,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from panoptes_aggregation==4.1.0) (1.26.2)\n",
            "Requirement already satisfied: packaging<23.3,>=20.1 in /usr/local/lib/python3.10/dist-packages (from panoptes_aggregation==4.1.0) (23.2)\n",
            "Collecting pandas<2.1.4,>=1.4.0 (from panoptes_aggregation==4.1.0)\n",
            "  Using cached pandas-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: progressbar2<4.3,>=3.39 in /usr/local/lib/python3.10/dist-packages (from panoptes_aggregation==4.1.0) (4.2.0)\n",
            "Requirement already satisfied: python-levenshtein<0.24,>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from panoptes_aggregation==4.1.0) (0.23.0)\n",
            "Requirement already satisfied: python-slugify<8.1,>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from panoptes_aggregation==4.1.0) (8.0.4)\n",
            "Requirement already satisfied: pyyaml<6.1,>=6.0 in /usr/local/lib/python3.10/dist-packages (from panoptes_aggregation==4.1.0) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn<1.3.3,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from panoptes_aggregation==4.1.0) (1.3.2)\n",
            "Requirement already satisfied: scipy<1.11.4,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from panoptes_aggregation==4.1.0) (1.11.3)\n",
            "Requirement already satisfied: werkzeug<3.0.2,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from panoptes_aggregation==4.1.0) (3.0.1)\n",
            "Requirement already satisfied: shapely<2.0.3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from panoptes_aggregation==4.1.0) (2.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<4.13,>=4.8.1->panoptes_aggregation==4.1.0) (2.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from collatex<2.4,>=2.3->panoptes_aggregation==4.1.0) (3.4.2)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from collatex<2.4,>=2.3->panoptes_aggregation==4.1.0) (3.11.0)\n",
            "Requirement already satisfied: cython<3,>=0.27 in /usr/local/lib/python3.10/dist-packages (from hdbscan<=0.8.33,>=0.8.20->panoptes_aggregation==4.1.0) (0.29.37)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan<=0.8.33,>=0.8.20->panoptes_aggregation==4.1.0) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1.4,>=1.4.0->panoptes_aggregation==4.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1.4,>=1.4.0->panoptes_aggregation==4.1.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1.4,>=1.4.0->panoptes_aggregation==4.1.0) (2024.2)\n",
            "Requirement already satisfied: python-utils>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from progressbar2<4.3,>=3.39->panoptes_aggregation==4.1.0) (3.9.0)\n",
            "Requirement already satisfied: Levenshtein==0.23.0 in /usr/local/lib/python3.10/dist-packages (from python-levenshtein<0.24,>=0.21.0->panoptes_aggregation==4.1.0) (0.23.0)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.23.0->python-levenshtein<0.24,>=0.21.0->panoptes_aggregation==4.1.0) (3.10.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify<8.1,>=7.0.0->panoptes_aggregation==4.1.0) (1.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.3.3,>=1.2.0->panoptes_aggregation==4.1.0) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug<3.0.2,>=2.3.0->panoptes_aggregation==4.1.0) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.1.4,>=1.4.0->panoptes_aggregation==4.1.0) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>3.10.0.2 in /usr/local/lib/python3.10/dist-packages (from python-utils>=3.0.0->progressbar2<4.3,>=3.39->panoptes_aggregation==4.1.0) (4.12.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->collatex<2.4,>=2.3->panoptes_aggregation==4.1.0) (0.2.13)\n",
            "Using cached pandas-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "Building wheels for collected packages: panoptes_aggregation\n",
            "  Building wheel for panoptes_aggregation (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for panoptes_aggregation: filename=panoptes_aggregation-4.1.0-py3-none-any.whl size=281362 sha256=cec4a3d954d7620aa48b42b00c9d2a70589ed50358e0950d2351f5f97a7791db\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qm7_9kjb/wheels/82/1b/51/449c26fa2dfc55badd050f43a13a9fde5487443121113dc2c5\n",
            "Successfully built panoptes_aggregation\n",
            "Installing collected packages: pandas, panoptes_aggregation\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.3 which is incompatible.\n",
            "mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 2.1.3 which is incompatible.\n",
            "plotnine 0.14.1 requires pandas>=2.2.0, but you have pandas 2.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.1.3 panoptes_aggregation-4.1.0\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Final Setup Verification\n",
        "⚠️ RESTART RUNTIME AGAIN BEFORE RUNNING THIS CELL"
      ],
      "metadata": {
        "id": "667TtQ2Lz2nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import panoptes_aggregation\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"Panoptes aggregation version: {panoptes_aggregation.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "-JstxvA4z3Wn",
        "outputId": "eae3a710-0ad7-4631-dd40-c9d3198c956a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'panoptes_aggregation'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ee37a5b6b367>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpanoptes_aggregation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Pandas version: {pd.__version__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Panoptes aggregation version: {panoptes_aggregation.__version__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'panoptes_aggregation'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration"
      ],
      "metadata": {
        "id": "-itrQBW0z8-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from panoptes_aggregation import extractors, reducers\n",
        "from panoptes_aggregation.running import setup_csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "ltpvW9l8z8uC",
        "outputId": "4f8af79e-db88-4a72-d526-84c750abee50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'panoptes_aggregation.running'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b52a9c1504d9>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpanoptes_aggregation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextractors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreducers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpanoptes_aggregation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msetup_csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'panoptes_aggregation.running'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define default character replacements\n",
        "DEFAULT_REPLACEMENTS = {\n",
        "    r'\\u2019': \"'\",    # smart apostrophe\n",
        "    r'\\u201c': '\"',    # opening smart quote\n",
        "    r'\\u201d': '\"',    # closing smart quote\n",
        "    r'\\u00e9': 'é',    # e acute\n",
        "    r'\\u00f1': 'ñ',    # n tilde\n",
        "    r'\\n': ' ',        # newline to space\n",
        "    r'\\t': ' ',        # tab to space\n",
        "    r'\\\"': '\"',        # escaped quote\n",
        "    r'\\\\': '',         # backslash\n",
        "    r'\\r': ' ',        # carriage return\n",
        "    r'\\u00a0': ' ',    # non-breaking space\n",
        "    r'\\u2013': '-',    # en dash\n",
        "    r'\\u2014': '--',   # em dash\n",
        "}\n",
        "\n",
        "# Add your custom replacements here\n",
        "CUSTOM_REPLACEMENTS = {\n",
        "    # Example:\n",
        "    # r'\\u00fc': 'ü',  # u umlaut\n",
        "}\n",
        "\n",
        "# Combine both dictionaries\n",
        "ALL_REPLACEMENTS = {**DEFAULT_REPLACEMENTS, **CUSTOM_REPLACEMENTS}"
      ],
      "metadata": {
        "id": "zFO-uj5N0JKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your workflow parameters\n",
        "# Replace these with your values\n",
        "WORKFLOW_ID = \"ENTER_YOUR_WORKFLOW_ID\"\n",
        "WORKFLOW_VERSION = \"ENTER_YOUR_WORKFLOW_VERSION\"\n",
        "\n",
        "# Directory for output files\n",
        "OUTPUT_DIR = \"aggregated_output\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "b0r07Vi10Ny9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate configuration from workflow CSV\n",
        "try:\n",
        "    # Replace 'workflow.csv' with your workflow CSV filename\n",
        "    config = setup_csv.Config('workflow.csv', workflow_id=WORKFLOW_ID, version=WORKFLOW_VERSION)\n",
        "    print(f\"Configuration generated for workflow {WORKFLOW_ID} version {WORKFLOW_VERSION}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error generating configuration: {str(e)}\")\n",
        "    print(\"Check your workflow CSV file and workflow ID/version\")\n"
      ],
      "metadata": {
        "id": "jdpN2EBA0TZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract"
      ],
      "metadata": {
        "id": "25zm9dVs0V-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Replace 'classifications.csv' with your classifications CSV filename\n",
        "    with open(config.extractor_config, 'r') as conf_file:\n",
        "        extractor_config = json.load(conf_file)\n",
        "\n",
        "    # Run the extractor\n",
        "    print(\"Extracting classifications...\")\n",
        "    extracted_data = extractors.extract_csv(\n",
        "        'classifications.csv',\n",
        "        extractor_config,\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        show_progress=True\n",
        "    )\n",
        "    print(\"Extraction complete!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during extraction: {str(e)}\")\n",
        "    print(\"Check your classifications CSV file\")"
      ],
      "metadata": {
        "id": "IfERYmYy0WyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reduce"
      ],
      "metadata": {
        "id": "8rYSl1_X0bee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    print(\"Reducing extracted data...\")\n",
        "    reduced_data = reducers.reduce_csv(\n",
        "        extracted_data['data_file'],\n",
        "        extractor_config['reducer'],\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        show_progress=True\n",
        "    )\n",
        "    print(\"Reduction complete!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during reduction: {str(e)}\")"
      ],
      "metadata": {
        "id": "scA1aTSU0ZK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean and Export Results"
      ],
      "metadata": {
        "id": "1IWnWbSC0i_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"Clean text by replacing special characters and formatting.\"\"\"\n",
        "    cleaned = text\n",
        "    for pattern, replacement in ALL_REPLACEMENTS.items():\n",
        "        cleaned = cleaned.replace(pattern, replacement)\n",
        "    return cleaned\n",
        "\n",
        "def scan_for_special_chars(text):\n",
        "    \"\"\"Scan for any remaining escaped unicode or special characters.\"\"\"\n",
        "    # Look for \\u followed by exactly 4 hex digits\n",
        "    unicode_chars = set(re.findall(r'\\\\u[0-9a-fA-F]{4}', text))\n",
        "    # Look for escaped characters\n",
        "    escaped_chars = set(re.findall(r'\\\\[^u]', text))\n",
        "    return unicode_chars, escaped_chars"
      ],
      "metadata": {
        "id": "seIaMmzF0j_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def export_results():\n",
        "    try:\n",
        "        # Load reduced data\n",
        "        with open(reduced_data['data_file'], 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        print(f\"Exporting {len(data)} subjects to text files...\")\n",
        "        special_chars_found = set()\n",
        "        escaped_chars_found = set()\n",
        "\n",
        "        # Process each subject\n",
        "        for subject in tqdm(data):\n",
        "            subject_id = subject['subject_id']\n",
        "            answers = subject['data']  # Adjust this based on your data structure\n",
        "\n",
        "            # Clean the text\n",
        "            cleaned_answers = clean_text(json.dumps(answers, ensure_ascii=False))\n",
        "\n",
        "            # Scan for any remaining special characters\n",
        "            unicode_chars, escaped_chars = scan_for_special_chars(cleaned_answers)\n",
        "            special_chars_found.update(unicode_chars)\n",
        "            escaped_chars_found.update(escaped_chars)\n",
        "\n",
        "            # Write to file\n",
        "            output_file = os.path.join(OUTPUT_DIR, f\"subject_{subject_id}.txt\")\n",
        "            with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                f.write(cleaned_answers)\n",
        "\n",
        "        print(\"\\nExport complete!\")\n",
        "\n",
        "        # Report any found special characters\n",
        "        if special_chars_found or escaped_chars_found:\n",
        "            print(\"\\nFound additional characters that might need replacement:\")\n",
        "            if special_chars_found:\n",
        "                print(\"\\nUnicode characters:\")\n",
        "                for char in sorted(special_chars_found):\n",
        "                    print(f\"    {char}\")\n",
        "            if escaped_chars_found:\n",
        "                print(\"\\nEscaped characters:\")\n",
        "                for char in sorted(escaped_chars_found):\n",
        "                    print(f\"    {char}\")\n",
        "\n",
        "            print(\"\\nTo handle these, add them to CUSTOM_REPLACEMENTS above.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during export: {str(e)}\")\n",
        "\n",
        "# Run the export\n",
        "export_results()"
      ],
      "metadata": {
        "id": "DlWyIp9T0pSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verify Results"
      ],
      "metadata": {
        "id": "n0CxV5TD0rwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_results():\n",
        "    try:\n",
        "        # Load reduced data to get expected subject count\n",
        "        with open(reduced_data['data_file'], 'r') as f:\n",
        "            data = json.load(f)\n",
        "        expected_count = len(data)\n",
        "\n",
        "        # Count actual files\n",
        "        actual_files = len([f for f in os.listdir(OUTPUT_DIR)\n",
        "                          if f.startswith('subject_') and f.endswith('.txt')])\n",
        "\n",
        "        print(f\"Expected files: {expected_count}\")\n",
        "        print(f\"Created files: {actual_files}\")\n",
        "\n",
        "        if expected_count == actual_files:\n",
        "            print(\"✅ All files successfully created!\")\n",
        "        else:\n",
        "            print(\"⚠️ Warning: Number of files doesn't match expected count\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during verification: {str(e)}\")\n",
        "\n",
        "# Run verification\n",
        "verify_results()"
      ],
      "metadata": {
        "id": "lCFwSV6Y0siq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Troubleshooting\n",
        "\n",
        "If you encounter issues:\n",
        "\n",
        "1. **Package Version Conflicts**\n",
        "   - Return to Step 1 of Initial Setup\n",
        "   - Follow all steps in order\n",
        "   - Make sure to restart runtime when indicated\n",
        "\n",
        "2. **Import Errors**\n",
        "   - Make sure you've restarted the runtime after installing packages\n",
        "   - Verify pandas version is 2.2.2\n",
        "   - Try running the setup steps again from the beginning\n",
        "\n",
        "3. **File Upload Issues**\n",
        "   - Make sure your CSV files are uploaded to Colab\n",
        "   - Verify the filenames match what's in your code\n",
        "   - Check file permissions\n",
        "\n",
        "4. **Memory Issues**\n",
        "   - Try restarting the runtime\n",
        "   - Consider using a smaller dataset for testing\n",
        "   - Clear output of previous cells\n",
        "\n",
        "Remember: Always restart the runtime when indicated, and run cells in order!"
      ],
      "metadata": {
        "id": "qe5MYNT30xv6"
      }
    }
  ]
}